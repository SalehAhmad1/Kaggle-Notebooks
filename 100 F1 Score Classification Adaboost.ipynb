{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/i200605salehahmad/100-f1-score-classification-adaboost?scriptVersionId=131127474\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install lazypredict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport lazypredict\nfrom lazypredict.Supervised import LazyClassifier","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.012301Z","iopub.execute_input":"2023-05-21T12:02:01.01271Z","iopub.status.idle":"2023-05-21T12:02:01.020646Z","shell.execute_reply.started":"2023-05-21T12:02:01.012679Z","shell.execute_reply":"2023-05-21T12:02:01.019277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/easiest-diabetes-classification-dataset/Diabetes Classification.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.024726Z","iopub.execute_input":"2023-05-21T12:02:01.025435Z","iopub.status.idle":"2023-05-21T12:02:01.098213Z","shell.execute_reply.started":"2023-05-21T12:02:01.025395Z","shell.execute_reply":"2023-05-21T12:02:01.097103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop('Diagnosis', axis=1)\nY = df['Diagnosis']\n\nnp.shape(X), np.shape(Y)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.100429Z","iopub.execute_input":"2023-05-21T12:02:01.100862Z","iopub.status.idle":"2023-05-21T12:02:01.112714Z","shell.execute_reply.started":"2023-05-21T12:02:01.100819Z","shell.execute_reply":"2023-05-21T12:02:01.11151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check for nulls in the dataset\nX.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.114581Z","iopub.execute_input":"2023-05-21T12:02:01.115078Z","iopub.status.idle":"2023-05-21T12:02:01.130474Z","shell.execute_reply.started":"2023-05-21T12:02:01.115011Z","shell.execute_reply":"2023-05-21T12:02:01.129305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AllNumericalCols = [col for col in X.columns if df[col].dtypes!='O']\nAllNumericalCols","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.133387Z","iopub.execute_input":"2023-05-21T12:02:01.133792Z","iopub.status.idle":"2023-05-21T12:02:01.147341Z","shell.execute_reply.started":"2023-05-21T12:02:01.133757Z","shell.execute_reply":"2023-05-21T12:02:01.146107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AllCategoricalCols = set(X.columns) - set(AllNumericalCols)\nAllCategoricalCols","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.148797Z","iopub.execute_input":"2023-05-21T12:02:01.149259Z","iopub.status.idle":"2023-05-21T12:02:01.162532Z","shell.execute_reply.started":"2023-05-21T12:02:01.149217Z","shell.execute_reply":"2023-05-21T12:02:01.161267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NOrmalize numerical columns\nscaler = StandardScaler()\nX[AllNumericalCols] = scaler.fit_transform(X[AllNumericalCols])\nX","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.16384Z","iopub.execute_input":"2023-05-21T12:02:01.164297Z","iopub.status.idle":"2023-05-21T12:02:01.202256Z","shell.execute_reply.started":"2023-05-21T12:02:01.164255Z","shell.execute_reply":"2023-05-21T12:02:01.200966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label Encode Categorical Columns\nLE = LabelEncoder()\nfor idxcol,col in enumerate(AllCategoricalCols):\n    X[col] = LE.fit_transform(X[col])\nX","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.203562Z","iopub.execute_input":"2023-05-21T12:02:01.204042Z","iopub.status.idle":"2023-05-21T12:02:01.232461Z","shell.execute_reply.started":"2023-05-21T12:02:01.203988Z","shell.execute_reply":"2023-05-21T12:02:01.231116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n\nnp.shape(X_train),np.shape(X_test),np.shape(Y_train),np.shape(Y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.233844Z","iopub.execute_input":"2023-05-21T12:02:01.234192Z","iopub.status.idle":"2023-05-21T12:02:01.248406Z","shell.execute_reply.started":"2023-05-21T12:02:01.234161Z","shell.execute_reply":"2023-05-21T12:02:01.247194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Call Lazy Predict\nLZ = LazyClassifier()\nmodels,predictions = LZ.fit(X_train, X_test, Y_train, Y_test)\nmodels","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:01.249806Z","iopub.execute_input":"2023-05-21T12:02:01.250164Z","iopub.status.idle":"2023-05-21T12:02:02.482174Z","shell.execute_reply.started":"2023-05-21T12:02:01.250133Z","shell.execute_reply":"2023-05-21T12:02:02.48097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# As from lazy predict top classifier is Adaboost so, calling ada boost on another set of train and test splits","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n\nmodel = AdaBoostClassifier()\nmodel.fit(X_train, Y_train)\nY_pred = model.predict(X_test)\n\nacc = accuracy_score(Y_test, Y_pred)*100\nprec = precision_score(Y_test, Y_pred, average='macro')*100\nrec = recall_score(Y_test, Y_pred, average='macro')*100\nf1 = f1_score(Y_test, Y_pred, average='macro')*100\n\nprint(\"Accuracy: \", acc)\nprint(\"Precision: \", prec)\nprint(\"Recall: \", rec)\nprint(\"F1 Score: \", f1)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:02:02.485633Z","iopub.execute_input":"2023-05-21T12:02:02.486114Z","iopub.status.idle":"2023-05-21T12:02:02.626674Z","shell.execute_reply.started":"2023-05-21T12:02:02.486068Z","shell.execute_reply":"2023-05-21T12:02:02.625582Z"},"trusted":true},"execution_count":null,"outputs":[]}]}